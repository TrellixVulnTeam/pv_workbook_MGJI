{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:15:50.146285Z",
     "start_time": "2020-05-15T20:15:48.451174Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toddhendricks/miniconda3/envs/metis/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import various packages\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from bson.son import SON\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt\n",
    "\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from pprint import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:15:38.541108Z",
     "start_time": "2020-05-15T20:15:29.757213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting corextopic\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/da/c68f01915c86061b55c8cbe0bc092999a5444eef5b10abf69a0d1e06b6c3/corextopic-1.0.5.tar.gz\n",
      "Building wheels for collected packages: corextopic\n",
      "  Building wheel for corextopic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for corextopic: filename=corextopic-1.0.5-cp37-none-any.whl size=22531 sha256=b935eee514c2c1682086f1b9d99104c92520ac69f5a6c1484682ea661fede8e9\n",
      "  Stored in directory: /Users/toddhendricks/Library/Caches/pip/wheels/a8/1c/04/7f75e4433b37b770736e7cd017775fb997b9f3222b120da15f\n",
      "Successfully built corextopic\n",
      "Installing collected packages: corextopic\n",
      "Successfully installed corextopic-1.0.5\n",
      "Requirement already satisfied: networkx in /Users/toddhendricks/miniconda3/envs/metis/lib/python3.7/site-packages (2.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/toddhendricks/miniconda3/envs/metis/lib/python3.7/site-packages (from networkx) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install corextopic\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:27.759086Z",
     "start_time": "2020-05-15T20:12:26.987743Z"
    }
   },
   "outputs": [],
   "source": [
    "commits = !curl -H \"Authorization: token 1058698d042f7b0937cc79ed498de96806a79c9f\" https://api.github.com/repos/apache/arrow/commits > commits.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:29.113266Z",
     "start_time": "2020-05-15T20:12:27.762461Z"
    }
   },
   "outputs": [],
   "source": [
    "prs = !curl -H \"Authorization: token 1058698d042f7b0937cc79ed498de96806a79c9f\" https://api.github.com/repos/apache/arrow/pulls > prs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:29.813399Z",
     "start_time": "2020-05-15T20:12:29.117315Z"
    }
   },
   "outputs": [],
   "source": [
    "commit_comments = !curl -H \"Authorization: token 1058698d042f7b0937cc79ed498de96806a79c9f\" https://api.github.com/repos/apache/arrow/comments > commit_comments.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:29.829441Z",
     "start_time": "2020-05-15T20:12:29.815944Z"
    }
   },
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:29.961674Z",
     "start_time": "2020-05-15T20:12:29.831561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'arrow', 'author', 'catalog', 'config', 'local', 'outings']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:29.989955Z",
     "start_time": "2020-05-15T20:12:29.972606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pr', 'comments', 'commits']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client.arrow\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.025827Z",
     "start_time": "2020-05-15T20:12:30.003175Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def scrub_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('arrow','', text)\n",
    "    text = re.sub('closes','', text)\n",
    "    text = re.sub('ns','', text)\n",
    "    text = re.sub('05','', text)\n",
    "    text = re.sub('src','', text)\n",
    "    text = re.sub('cpp','', text)\n",
    "    text = re.sub('pr','', text)\n",
    "    text = re.sub('ishizaki','', text)\n",
    "    text = re.sub('authored','', text)\n",
    "    text = re.sub('signed','', text)\n",
    "    text = re.sub('00','', text)\n",
    "    text = re.sub('com','', text)\n",
    "    text = re.sub('antoine','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.102098Z",
     "start_time": "2020-05-15T20:12:30.036570Z"
    }
   },
   "outputs": [],
   "source": [
    "pull_requests = list(db.pr.find({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.111585Z",
     "start_time": "2020-05-15T20:12:30.106558Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_titles = []\n",
    "for pr in pull_requests:\n",
    "    title = pr.get('title','No Title')\n",
    "    pr_titles.append(title)\n",
    "    \n",
    "pr_messages = []\n",
    "for pr in pull_requests:\n",
    "    body = pr.get('body','No body')\n",
    "    pr_messages.append(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.138853Z",
     "start_time": "2020-05-15T20:12:30.123337Z"
    }
   },
   "outputs": [],
   "source": [
    "commits = list(db.commits.find({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.146532Z",
     "start_time": "2020-05-15T20:12:30.141307Z"
    }
   },
   "outputs": [],
   "source": [
    "commit_dict = []\n",
    "for commit in commits:\n",
    "    message = commit.get('commit','No commit')\n",
    "    commit_dict.append(message)\n",
    "commit_messages = [item['message'] for item in commit_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.168987Z",
     "start_time": "2020-05-15T20:12:30.159454Z"
    }
   },
   "outputs": [],
   "source": [
    "commentary = list(db.comments.find({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.178085Z",
     "start_time": "2020-05-15T20:12:30.171462Z"
    }
   },
   "outputs": [],
   "source": [
    "commit_commentary = []\n",
    "for comment in commentary:\n",
    "    c = comment.get('body','No body')\n",
    "    commit_commentary.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.195637Z",
     "start_time": "2020-05-15T20:12:30.181506Z"
    }
   },
   "outputs": [],
   "source": [
    "commit_messages = list(map(scrub_text,commit_messages))\n",
    "commit_commentary = list(map(scrub_text,commit_commentary))\n",
    "pr_titles = list(map(scrub_text,pr_titles))\n",
    "pr_messages = list(map(scrub_text,pr_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.207841Z",
     "start_time": "2020-05-15T20:12:30.201190Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_text = commit_messages + commit_commentary + pr_titles + pr_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.229464Z",
     "start_time": "2020-05-15T20:12:30.210212Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_label = [e[:40]+\"...\" for e in combined_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.244794Z",
     "start_time": "2020-05-15T20:12:30.236778Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('combined_repo_data.pickle', 'wb') as f:\n",
    "    pickle.dump(combined_text,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.322669Z",
     "start_time": "2020-05-15T20:12:30.252100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>0128</th>\n",
       "      <th>0134</th>\n",
       "      <th>0177</th>\n",
       "      <th>02</th>\n",
       "      <th>0260</th>\n",
       "      <th>027</th>\n",
       "      <th>03</th>\n",
       "      <th>033</th>\n",
       "      <th>036</th>\n",
       "      <th>...</th>\n",
       "      <th>x10</th>\n",
       "      <th>x86</th>\n",
       "      <th>xhochy</th>\n",
       "      <th>xxx</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yibo</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-8758: [r] updates for patibility with dplyr 1.0\\n\\ni tested this locally with the current version of `dplyr` on cran and the dev version scheduled to be released to cran on may 15. our tests now pass with both versio.\\n\\nchanges addressed:\\n\\n* `group_by` now requires a character vector of grouping variable names, so now we use `group_vars()` itead of `groups()`. `group_vars()` works in the current `dplyr` release, so this is a simple change.\\n* the argument name in `group_by()` changed from `add` to `.add`, and calling it with the name that works in the current version raises a deecation warning in dplyr 1.0. the fix here supports both spellings of the argument, and it avoids the warning by determining which version of the internal dplyr function exists and calling the apoiate one.\\n* `dplyr::tramute()` no longer calls `dplyr::mutate()` internally, so it doesn't just work on  objects anymore. i skipped the one test that called it and left a todo to add a tramute method.\\n\\n #7147 from nealrichardson/dplyr-1.0\\n\\n-by: neal richardson &lt;neal.p.richardson@gmail.&gt;\\n-off-by: neal richardson &lt;neal.p.richardson@gmail.&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8745: [c++] enhance bitmap::tostring test for big-endian platforms\\n\\nthis  fixes the failure of `bitmap::tostring` that currently takes care of little-endian platforms. this test was added by #6987\\n\\nthis  updates the test using an endian-agnostic implementation.\\n\\n #7134 from kiszk/-8745\\n\\n-by: kazuaki  &lt;@jp.ibm.&gt;\\n-off-by:  pitrou &lt;@python.org&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8756: [c++] fix bitmap words tests' failures on big-endian platforms\\n\\nthis  adds support of multiple-word operation on big-endian platforms. there are optimized code to concat multiple words into one word with bit shift operatio. the current code assumes a little-endian platform.\\nthis code support bit-endian by adding conversio between little-endian and big-endian. this is because the shift operatio assume the little-endian layout. it is easy to implement by adding conversio.\\n\\nwith #7136 and this , the following failures in -utility-test will be fixed.\\n```\\n[  failed  ] bitmap.visitwordsand\\n[  failed  ] bitmap.shiftingwordsoptimization\\n```\\n\\n #7145 from kiszk/-8756\\n\\nlead--by: kazuaki  &lt;@jp.ibm.&gt;\\nco--by:  pitrou &lt;@python.org&gt;\\n-off-by:  pitrou &lt;@python.org&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1836 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    01  0128  0134  0177  02  \\\n",
       "-8758: [r] updates for patibility with dplyr 1....   0     0     0     0   0   \n",
       "-8745: [c++] enhance bitmap::tostring test for ...   0     0     0     0   0   \n",
       "-8756: [c++] fix bitmap words tests' failures o...   0     0     0     0   0   \n",
       "\n",
       "                                                    0260  027  03  033  036  \\\n",
       "-8758: [r] updates for patibility with dplyr 1....     0    0   0    0    0   \n",
       "-8745: [c++] enhance bitmap::tostring test for ...     0    0   0    0    0   \n",
       "-8756: [c++] fix bitmap words tests' failures o...     0    0   0    0    0   \n",
       "\n",
       "                                                    ...  x10  x86  xhochy  \\\n",
       "-8758: [r] updates for patibility with dplyr 1....  ...    0    0       0   \n",
       "-8745: [c++] enhance bitmap::tostring test for ...  ...    0    0       0   \n",
       "-8756: [c++] fix bitmap words tests' failures o...  ...    0    0       0   \n",
       "\n",
       "                                                    xxx  yeah  yep  yes  yibo  \\\n",
       "-8758: [r] updates for patibility with dplyr 1....    0     0    0    0     0   \n",
       "-8745: [c++] enhance bitmap::tostring test for ...    0     0    0    0     0   \n",
       "-8756: [c++] fix bitmap words tests' failures o...    0     0    0    0     0   \n",
       "\n",
       "                                                    yup  zero  \n",
       "-8758: [r] updates for patibility with dplyr 1....    0     0  \n",
       "-8745: [c++] enhance bitmap::tostring test for ...    0     0  \n",
       "-8756: [c++] fix bitmap words tests' failures o...    0     0  \n",
       "\n",
       "[3 rows x 1836 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words= 'english',max_df=0.05)\n",
    "doc_word = vectorizer.fit_transform(combined_text)\n",
    "pd.DataFrame(doc_word.toarray(), index=combined_text, columns=vectorizer.get_feature_names()).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.438418Z",
     "start_time": "2020-05-15T20:12:30.325070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63181307, 0.21296267])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(2)\n",
    "lsa_doc_topic = lsa.fit_transform(doc_word)\n",
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.479938Z",
     "start_time": "2020-05-15T20:12:30.440258Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf_model = NMF(6)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.500617Z",
     "start_time": "2020-05-15T20:12:30.491219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.62948849e-03, 8.98209917e-03, 2.32982402e-04, 1.43066891e-02,\n",
       "        4.55313286e-02, 1.78412291e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.54239495e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.42888640e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.57718543e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 7.52201349e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.23878255e-04, 6.81974325e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.02785702e-03, 5.51643370e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.88405429e-04, 7.54828620e-04]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.592260Z",
     "start_time": "2020-05-15T20:12:30.531178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>0128</th>\n",
       "      <th>0134</th>\n",
       "      <th>0177</th>\n",
       "      <th>02</th>\n",
       "      <th>0260</th>\n",
       "      <th>027</th>\n",
       "      <th>03</th>\n",
       "      <th>033</th>\n",
       "      <th>036</th>\n",
       "      <th>...</th>\n",
       "      <th>x10</th>\n",
       "      <th>x86</th>\n",
       "      <th>xhochy</th>\n",
       "      <th>xxx</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yibo</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>component_1</th>\n",
       "      <td>0.139</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 1836 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                01  0128  0134  0177     02  0260   027    03   033   036  \\\n",
       "component_1  0.139  0.07  0.07  0.07  0.139  0.07  0.07  0.07  0.07  0.07   \n",
       "component_2  0.000  0.00  0.00  0.00  0.000  0.00  0.00  0.00  0.00  0.00   \n",
       "component_3  0.000  0.00  0.00  0.00  0.000  0.00  0.00  0.00  0.00  0.00   \n",
       "component_4  0.000  0.00  0.00  0.00  0.000  0.00  0.00  0.00  0.00  0.00   \n",
       "component_5  0.000  0.00  0.00  0.00  0.000  0.00  0.00  0.00  0.00  0.00   \n",
       "component_6  0.000  0.00  0.00  0.00  0.000  0.00  0.00  0.00  0.00  0.00   \n",
       "\n",
       "             ...    x10    x86  xhochy    xxx   yeah  yep    yes   yibo  yup  \\\n",
       "component_1  ...  0.000  0.000   0.000  0.000  0.000  0.0  0.000  0.000  0.0   \n",
       "component_2  ...  0.000  0.000   0.000  0.000  0.000  0.0  0.000  0.000  0.0   \n",
       "component_3  ...  0.000  0.000   0.000  0.001  0.000  0.0  0.000  0.000  0.0   \n",
       "component_4  ...  0.889  0.296   0.000  0.000  0.000  0.0  0.000  0.000  0.0   \n",
       "component_5  ...  0.000  0.000   0.001  0.007  0.004  0.0  0.001  0.000  0.0   \n",
       "component_6  ...  0.000  0.000   0.000  0.008  0.002  0.0  0.001  0.012  0.0   \n",
       "\n",
       "             zero  \n",
       "component_1   0.0  \n",
       "component_2   0.0  \n",
       "component_3   0.0  \n",
       "component_4   0.0  \n",
       "component_5   0.0  \n",
       "component_6   0.0  \n",
       "\n",
       "[6 rows x 1836 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = pd.DataFrame(nmf_model.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\",\"component_3\",\"component_4\",\"component_5\",\"component_6\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.607638Z",
     "start_time": "2020-05-15T20:12:30.597116Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "            for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.628206Z",
     "start_time": "2020-05-15T20:12:30.610395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "high, mild, time, outliers, measurements, severe\n",
      "\n",
      "Topic  1\n",
      "51, sec, start, passed, pute, dataset\n",
      "\n",
      "Topic  2\n",
      "testplasmaserialization, plasma, home, ms, serialization_tests, cc\n",
      "\n",
      "Topic  3\n",
      "bytes_per_second, cpu, benchmark, time, x10, validatelargeascii\n",
      "\n",
      "Topic  4\n",
      "schema, true, type, nullable, field, type_type\n",
      "\n",
      "Topic  5\n",
      "endian, little, failed, failures, big, format\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_model, vectorizer.get_feature_names(), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.679922Z",
     "start_time": "2020-05-15T20:12:30.669873Z"
    }
   },
   "outputs": [],
   "source": [
    "H = pd.DataFrame(doc_topic.round(5),\n",
    "             index = ex_label,\n",
    "             columns = [\"component_1\",\"component_2\",\"component_3\",\"component_4\",\"component_5\",\"component_6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:30.743367Z",
     "start_time": "2020-05-15T20:12:30.689072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "      <th>component_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-8758: [r] updates for patibility with d...</th>\n",
       "      <td>0.00863</td>\n",
       "      <td>0.00898</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.01431</td>\n",
       "      <td>0.04553</td>\n",
       "      <td>0.17841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8745: [c++] enhance bitmap::tostring te...</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00254</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.94289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8756: [c++] fix bitmap words tests' fai...</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.57719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-4018: [c++] fix rle tests' failures on ...</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.03565</td>\n",
       "      <td>0.02523</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.44042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8759: [c++][plasma] fix testplasmaseria...</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00031</td>\n",
       "      <td>8.27484</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok, will add in my `integration` branch....</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00437</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes...</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shouldn't this be like the default `::ti...</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>0.00068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isn't this excatly like `writeimitive` a...</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.00055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shouldn't this (and `timestamp`) return ...</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.00075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             component_1  component_2  \\\n",
       "-8758: [r] updates for patibility with d...      0.00863      0.00898   \n",
       "-8745: [c++] enhance bitmap::tostring te...      0.00000      0.00000   \n",
       "-8756: [c++] fix bitmap words tests' fai...      0.00000      0.00000   \n",
       "-4018: [c++] fix rle tests' failures on ...      0.00000      0.00048   \n",
       "-8759: [c++][plasma] fix testplasmaseria...      0.00000      0.00031   \n",
       "...                                                  ...          ...   \n",
       "ok, will add in my `integration` branch....      0.00000      0.00000   \n",
       "yes...                                           0.00000      0.00000   \n",
       "shouldn't this be like the default `::ti...      0.00000      0.00075   \n",
       "isn't this excatly like `writeimitive` a...      0.00000      0.00000   \n",
       "shouldn't this (and `timestamp`) return ...      0.00000      0.00000   \n",
       "\n",
       "                                             component_3  component_4  \\\n",
       "-8758: [r] updates for patibility with d...      0.00023      0.01431   \n",
       "-8745: [c++] enhance bitmap::tostring te...      0.00254      0.00000   \n",
       "-8756: [c++] fix bitmap words tests' fai...      0.00000      0.00000   \n",
       "-4018: [c++] fix rle tests' failures on ...      0.03565      0.02523   \n",
       "-8759: [c++][plasma] fix testplasmaseria...      8.27484      0.00000   \n",
       "...                                                  ...          ...   \n",
       "ok, will add in my `integration` branch....      0.02333      0.00000   \n",
       "yes...                                           0.00000      0.00000   \n",
       "shouldn't this be like the default `::ti...      0.00000      0.00000   \n",
       "isn't this excatly like `writeimitive` a...      0.00000      0.00000   \n",
       "shouldn't this (and `timestamp`) return ...      0.00000      0.00000   \n",
       "\n",
       "                                             component_5  component_6  \n",
       "-8758: [r] updates for patibility with d...      0.04553      0.17841  \n",
       "-8745: [c++] enhance bitmap::tostring te...      0.00000      0.94289  \n",
       "-8756: [c++] fix bitmap words tests' fai...      0.00000      2.57719  \n",
       "-4018: [c++] fix rle tests' failures on ...      0.00000      2.44042  \n",
       "-8759: [c++][plasma] fix testplasmaseria...      0.00000      0.00000  \n",
       "...                                                  ...          ...  \n",
       "ok, will add in my `integration` branch....      0.00437      0.00000  \n",
       "yes...                                           0.00002      0.00009  \n",
       "shouldn't this be like the default `::ti...      0.00042      0.00068  \n",
       "isn't this excatly like `writeimitive` a...      0.00203      0.00055  \n",
       "shouldn't this (and `timestamp`) return ...      0.00039      0.00075  \n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:10:59.609501Z",
     "start_time": "2020-05-15T20:10:59.596321Z"
    }
   },
   "source": [
    "Try CorEx\n",
    "= = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:12:55.010938Z",
     "start_time": "2020-05-15T20:12:54.985600Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000,\n",
    "                             stop_words='english', token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                             binary=True)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(combined_text)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:16:00.029686Z",
     "start_time": "2020-05-15T20:15:56.836297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<corextopic.corextopic.Corex at 0x34324a7f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=6, words=words, seed=1)\n",
    "topic_model.fit(doc_word, words=words, docs=combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:17:26.413102Z",
     "start_time": "2020-05-15T20:17:26.395203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: tests,running,time,run,internal,array,json,ve,getting,having\n",
      "1: kazuaki,jp,ibm,batches,kiszk,endian,little,oducer,test,following\n",
      "2: failed,start,teor,utility,memory,fixed,sparse,messages,current,names\n",
      "3: use,gmail,kouhei,kou,sutou,clear,rust,ci,code,nevilledips\n",
      "4: read,figure,think,column,git,wes,way,non,mckinney,list\n",
      "5: title,implementation,expected,true,native,pandas,header,assume,wesm,python\n"
     ]
    }
   ],
   "source": [
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:59:08.736485Z",
     "start_time": "2020-05-15T20:59:08.726284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"-8758: [r] updates for patibility with dplyr 1.0\\n\\ni tested this locally with the current version of `dplyr` on cran and the dev version scheduled to be released to cran on may 15. our tests now pass with both versio.\\n\\nchanges addressed:\\n\\n* `group_by` now requires a character vector of grouping variable names, so now we use `group_vars()` itead of `groups()`. `group_vars()` works in the current `dplyr` release, so this is a simple change.\\n* the argument name in `group_by()` changed from `add` to `.add`, and calling it with the name that works in the current version raises a deecation warning in dplyr 1.0. the fix here supports both spellings of the argument, and it avoids the warning by determining which version of the internal dplyr function exists and calling the apoiate one.\\n* `dplyr::tramute()` no longer calls `dplyr::mutate()` internally, so it doesn't just work on  objects anymore. i skipped the one test that called it and left a todo to add a tramute method.\\n\\n #7147 from nealrichardson/dplyr-1.0\\n\\n-by: neal richardson <neal.p.richardson@gmail.>\\n-off-by: neal richardson <neal.p.richardson@gmail.>\",\n",
       "  0.0),\n",
       " ('-8743: [ci][c++] add a test job for s390x', 0.0),\n",
       " ('the patch is to implement validateascii function.\\r\\nthe benchmark and test facilities are also added.\\r\\n\\r\\n### the benchmark on x86:\\r\\n**original:**\\r\\n```\\r\\nrun on (20 x 30 mhz cpu s)\\r\\ncpu caches:\\r\\n  l1 data 32k (x10)\\r\\n  l1 itruction 32k (x10)\\r\\n  l2 unified 256k (x10)\\r\\n  l3 unified 256k (x1)\\r\\nload average: 4.79, 5.63, 2.68\\r\\n-----------------------------------------------------------------------------------\\r\\nbenchmark                         time             cpu   iteratio usercounters...\\r\\n-----------------------------------------------------------------------------------\\r\\nvalidatetinyascii              2.39          2.39     276349157 bytes_per_second=3.8964g/s\\r\\nvalidatetinynonascii           8.21          8.21      854219 bytes_per_second=1.24781g/s\\r\\nvalidatesmallascii             10.9          10.9      65497418 bytes_per_second=11.6721g/s\\r\\nvalidatesmallalmostascii       46.1          46.1      15204522 bytes_per_second=2.99142g/s\\r\\nvalidatesmallnonascii          84.6          84.6       8303767 bytes_per_second=1.47429g/s\\r\\nvalidatelargeascii             4997          4997        136960 bytes_per_second=18.6385g/s\\r\\nvalidatelargealmostascii      375         375         22651 bytes_per_second=3.04752g/s\\r\\nvalidatelargenonascii         73714         73713          9385 bytes_per_second=1.26467g/s\\r\\n\\r\\n```\\r\\n**enable simd**\\r\\n```\\r\\nrun on (20 x 30 mhz cpu s)\\r\\ncpu caches:\\r\\n  l1 data 32k (x10)\\r\\n  l1 itruction 32k (x10)\\r\\n  l2 unified 256k (x10)\\r\\n  l3 unified 256k (x1)\\r\\nload average: 4.79, 5.63, 2.68\\r\\n-----------------------------------------------------------------------------------\\r\\nbenchmark                         time             cpu   iteratio usercounters...\\r\\n-----------------------------------------------------------------------------------\\r\\nvalidatetinyascii              6.36          6.36     1259371 bytes_per_second=1.46438g/s\\r\\nvalidatetinynonascii           11.3          11.3      61604638 bytes_per_second=926.575m/s\\r\\nvalidatesmallascii             9.74          9.74      71987411 bytes_per_second=13.0987g/s\\r\\nvalidatesmallalmostascii       51.1          51.1      13677942 bytes_per_second=2.69774g/s\\r\\nvalidatesmallnonascii          84.5          84.5       8135065 bytes_per_second=1.47735g/s\\r\\nvalidatelargeascii             2363          2363        298863 bytes_per_second=39.4107g/s\\r\\nvalidatelargealmostascii      316         316         22642 bytes_per_second=3.8g/s\\r\\nvalidatelargenonascii         76222         76222          8703 bytes_per_second=1.223g/s\\r\\n```\\r\\n\\r\\n\\r\\n### the benchmark on arm64\\r\\n**original:**\\r\\n```\\r\\nrun on (46 x 26 mhz cpu s)\\r\\nload average: 0.19, 0.66, 1.73\\r\\n***warning*** cpu scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead.\\r\\n-----------------------------------------------------------------------------------\\r\\nbenchmark                         time             cpu   iteratio usercounters...\\r\\n-----------------------------------------------------------------------------------\\r\\nvalidatetinyascii              14.7          14.7      47461698 bytes_per_second=646.682m/s\\r\\nvalidatetinynonascii           48.0          48.0      14576733 bytes_per_second=218.46m/s\\r\\nvalidatesmallascii              109           109       6404395 bytes_per_second=1.1667g/s\\r\\nvalidatesmallalmostascii        275           275       2544737 bytes_per_second=513.185m/s\\r\\nvalidatesmallnonascii           555           555       1261830 bytes_per_second=230.408m/s\\r\\nvalidatelargeascii            78511         78502          8915 bytes_per_second=1.18649g/s\\r\\nvalidatelargealmostascii     179928        179907          3891 bytes_per_second=530.347m/s\\r\\nvalidatelargenonascii        415107        4158          1686 bytes_per_second=229.994m/s\\r\\n```\\r\\n**enable simd**\\r\\n```\\r\\nrun on (46 x 26 mhz cpu s)\\r\\nload average: 0.19, 0.66, 1.73\\r\\n***warning*** cpu scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead.\\r\\n-----------------------------------------------------------------------------------\\r\\nbenchmark                         time             cpu   iteratio usercounters...\\r\\n-----------------------------------------------------------------------------------\\r\\nvalidatetinyascii              65.9          65.9      197823 bytes_per_second=144.749m/s\\r\\nvalidatetinynonascii           48.0          48.0      14584553 bytes_per_second=218.732m/s\\r\\nvalidatesmallascii             83.7          83.7       8367346 bytes_per_second=1.52478g/s\\r\\nvalidatesmallalmostascii        275           275       2542186 bytes_per_second=512.498m/s\\r\\nvalidatesmallnonascii           555           555       1261774 bytes_per_second=230.301m/s\\r\\nvalidatelargeascii             3109          3108        225186 bytes_per_second=29.9637g/s\\r\\nvalidatelargealmostascii     179998        179974          3889 bytes_per_second=530.149m/s\\r\\nvalidatelargenonascii        414228        414181          1691 bytes_per_second=230.481m/s\\r\\n```\\r\\n\\r\\n `validatelargeascii` case will get performance boost when leveraging simd: \\r\\n\\r\\n- x86:      `18.6385g/s  -> 39.4107g/s`\\r\\n\\r\\n- arm64:  `1.18649g/s -> 29.9637g/s`\\r\\n\\r\\n',\n",
       "  0.0),\n",
       " ('the test only succeeds on c++.', 0.0),\n",
       " (\"the null shifting logic within plexobjectarrayreader is incorrect as it doesn't take into account the num_readers offset within the def_levels buffer. this results in failing assertio when a read spa more than one column chunk containing null values.\\r\\n\\r\\nwithout the change the added test will fail with\\r\\n\\r\\n```\\r\\nassertion failed: self.data.is_some()\\r\\nthread '::array_reader::tests::test_plex_array_reader_def_and_rep_levels' panicked at 'assertion failed: self.data.is_some()', parquet//data_type.rs:124:9\\r\\n```\\r\\n\\r\\nthis is due to the shifting logic resulting in the non-null `bytearray` values getting shifted out of alignment with where the definition levels state that non-null values should be found.\\r\\n\\r\\nunfortunately for the test i couldn't see an easy way to use the existing page helpers, as they assume imitive value types that can be generated randomly from a given range.\",\n",
       "  0.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_top_docs(topic=1, n_docs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:23:12.805667Z",
     "start_time": "2020-05-15T20:23:12.550307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(topic_model.tcs.shape[0]), topic_model.tcs, color='#4e79a7', width=0.5)\n",
    "plt.xlabel('Topic', fontsize=16)\n",
    "plt.ylabel('Total Correlation (nats)', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:36:26.623712Z",
     "start_time": "2020-05-15T20:36:22.661640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: start,extra,serialization,measurements,file,argument,summary,real,release,builds\n",
      "1: kouhei,kou,sutou,clear,make,retur,plasma,code,directory,removing\n",
      "2: benchmark,simd,time,running,variable,environment,docker,simple,passed,pass\n",
      "3: endian,kiszk,jp,kazuaki,ibm,big,little,pitrou,platforms,test\n",
      "4: schema,wes,mckinney,metadata,neville,nevilledips,pull,dipale,general,discussion\n",
      "5: tests,null,following,java,way,value,possible,title,able,getting\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=6, words=words,\n",
    "                       max_iter=200, verbose=False, seed=1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=combined_text, \n",
    "                anchors=[['measurements'], \n",
    "                         ['plasma'], \n",
    "                         ['benchmark'], \n",
    "                         ['endian'],\n",
    "                         ['schema']], anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:46:09.089210Z",
     "start_time": "2020-05-15T20:46:07.138750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: test,ibm,jp,kazuaki,kiszk,platforms,failed,read,big,internal\n",
      "1: test,kou,clear,sutou,kouhei,implementation,code,reading,doesn,unittest\n",
      "2: test,tests,endian,little,following,time,add,summary,adding,added\n",
      "3: test,pitrou,fix,org,ci,bitmap,version,error,buffer,python\n",
      "4: running,rust,gmail,itead,having,ve,messages,dipale,dataset,neville\n",
      "5: https,github,format,isn,apache,list,issues,krisztian,discussion,general\n",
      "6: file,able,type,things,ll,generated,flight,failing,minimal,easily\n",
      "7: data,need,title,figure,default,non,value,return,memory,getting\n"
     ]
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=8, words=words,\n",
    "                       max_iter=200, verbose=False, seed=1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=combined_text, \n",
    "                anchors=[['test'], ['test'], ['test'], ['test']], anchor_strength=5)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T20:54:05.752629Z",
     "start_time": "2020-05-15T20:54:05.736193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.206623368846365"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
