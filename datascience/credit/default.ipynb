{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tslearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/73/c49613d3d6a6e3b71561e4ea399200a83dff0a372559ecf36aa4aa86f80a/tslearn-0.4.1-cp37-cp37m-macosx_10_9_x86_64.whl (432kB)\n",
      "\u001b[K     |████████████████████████████████| 440kB 1.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.7/site-packages (from tslearn) (0.23.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.7/site-packages (from tslearn) (1.3.1)\n",
      "Requirement already satisfied: numba in /opt/anaconda3/lib/python3.7/site-packages (from tslearn) (0.45.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.7/site-packages (from tslearn) (0.13.2)\n",
      "Requirement already satisfied: Cython in /opt/anaconda3/lib/python3.7/site-packages (from tslearn) (0.29.13)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from tslearn) (1.17.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->tslearn) (2.1.0)\n",
      "Requirement already satisfied: llvmlite>=0.29.0dev0 in /opt/anaconda3/lib/python3.7/site-packages (from numba->tslearn) (0.29.0)\n",
      "Installing collected packages: tslearn\n",
      "Successfully installed tslearn-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install tslearn\n",
    "import pprint as pp\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, ShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score,confusion_matrix\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "                            make_scorer, fbeta_score, roc_curve, auc, \\\n",
    "                            roc_auc_score, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('UCI_Credit_Card 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = df[['PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = TimeSeriesKMeans(n_clusters=3, metric=\"euclidean\", max_iter=5,random_state=0).fit(payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
       "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'default.payment.next.month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tslearn/utils.py:91: UserWarning: 2-Dimensional data passed. Assuming these are 30000 1-dimensional timeseries\n",
      "  '{} 1-dimensional timeseries'.format(X.shape[0]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.predict(payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='kmeans')\n",
    "df['LIMIT_BAL'] = est.fit_transform(df[['LIMIT_BAL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    16286\n",
       "-1     5740\n",
       "-2     4895\n",
       " 2     2766\n",
       " 3      184\n",
       " 4       49\n",
       " 7       46\n",
       " 6       19\n",
       " 5       13\n",
       " 8        2\n",
       "Name: PAY_6, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PAY_6'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaulters = df[df['default.payment.next.month'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3995\n",
       "1.0    1653\n",
       "2.0     722\n",
       "3.0     248\n",
       "4.0      18\n",
       "Name: LIMIT_BAL, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaulters.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   48.7s finished\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'KNN': KNeighborsClassifier(), \n",
    "               'LR': LogisticRegression(penalty = 'l1', max_iter = 10000, solver = 'liblinear'), \n",
    "               'RF': RandomForestClassifier(max_depth = 3), \n",
    "               'SVM': svm.SVC()\n",
    "              }\n",
    "\n",
    "samplers = {'sampling': [None, \n",
    "                         SMOTE(random_state = 42), \n",
    "                         ADASYN(random_state = 42)]\n",
    "           }\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "# #n_splits = 1 in ShuffleSplits allows us to avoid cross-validation\n",
    "# #cross-validating with n_jobs = -1 with sampling is not possible with pipeline\n",
    "ss = ShuffleSplit(n_splits = 1)\n",
    "\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    steps = [('sampling', None),\n",
    "             (classifier_name, classifier)]\n",
    "    \n",
    "    model = Pipeline(steps)\n",
    "    \n",
    "    grid = GridSearchCV(model, samplers, cv = ss, \n",
    "                        n_jobs = -1, scoring = 'roc_auc', verbose = True)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    results = grid.cv_results_\n",
    "    \n",
    "    scores = list(zip(results['params'], results['mean_test_score']))\n",
    "    scores = sorted(scores, key = lambda x:x[1], reverse = True)\n",
    "\n",
    "    results_dict[classifier_name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNN': [({'sampling': SMOTE(random_state=42)}, 0.5935283367431283),\n",
      "         ({'sampling': ADASYN(random_state=42)}, 0.5897038369763554),\n",
      "         ({'sampling': None}, 0.5877791813940035)],\n",
      " 'LR': [({'sampling': None}, 0.7247687295692588),\n",
      "        ({'sampling': SMOTE(random_state=42)}, 0.692732771464787),\n",
      "        ({'sampling': ADASYN(random_state=42)}, 0.6903158286819809)],\n",
      " 'RF': [({'sampling': None}, 0.7441225926979698),\n",
      "        ({'sampling': ADASYN(random_state=42)}, 0.7371518980672336),\n",
      "        ({'sampling': SMOTE(random_state=42)}, 0.736865121838499)],\n",
      " 'SVM': [({'sampling': ADASYN(random_state=42)}, 0.6675946523421997),\n",
      "         ({'sampling': SMOTE(random_state=42)}, 0.6665021578962014),\n",
      "         ({'sampling': None}, 0.592328228679883)]}\n"
     ]
    }
   ],
   "source": [
    "sampling_results = results_dict\n",
    "pp.pprint(sampling_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed: 16.1min finished\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'KNN': KNeighborsClassifier(), \n",
    "               'LR': LogisticRegression(penalty = 'l1', max_iter = 10000, solver = 'liblinear'), \n",
    "               'RF': RandomForestClassifier(max_depth = 3), \n",
    "               'SVM': svm.SVC()\n",
    "              }\n",
    "\n",
    "param_dict = {'KNN': {'KNN__n_neighbors': [3, 5, 7]}, \n",
    "              'LR': {'LR__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, \n",
    "              'RF': {'RF__n_estimators': [100, 250, 500, 1000], \n",
    "                     'RF__max_depth': [3, 4, 5]},\n",
    "              'SVM': {'SVM__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "             }\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    \n",
    "    #sampling is the first step, then classifying\n",
    "    #'sampling' is None because no sampling was best\n",
    "    #if 'sampling' is not None, change n_jobs in GridSearchCV to 1\n",
    "    steps = [('sampling', None),\n",
    "             (classifier_name, classifier)]\n",
    "    \n",
    "    model = Pipeline(steps)\n",
    "    \n",
    "    #fetch the parameters from param_dict\n",
    "    params = param_dict[classifier_name]\n",
    "    \n",
    "    #scoring is changed to roc_auc score\n",
    "    #we specify return_train_score = True to \n",
    "    #compare train and test to check for overfitting\n",
    "    #if 'sampling' is not None, change n_jobs in GridSearchCV to 1\n",
    "    #this is to avoid conflict among the workers \n",
    "    #due to sampling and modeling the training set, which changes across folds\n",
    "    grid = GridSearchCV(model, params, cv = kf, return_train_score = True,\n",
    "                        n_jobs = -1, scoring = 'roc_auc', verbose = True)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    results = grid.cv_results_\n",
    "    \n",
    "    scores = list(zip(results['params'], results['mean_train_score'], results['mean_test_score']))\n",
    "    scores = sorted(scores, key = lambda x:x[2], reverse = True)\n",
    "\n",
    "    results_dict[classifier_name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNN': [({'KNN__n_neighbors': 7}, 0.7987196829215204, 0.6107601504510046),\n",
      "         ({'KNN__n_neighbors': 5}, 0.8298500560347524, 0.5998652638365873),\n",
      "         ({'KNN__n_neighbors': 3}, 0.8830195829419442, 0.5822575005123554)],\n",
      " 'LR': [({'LR__C': 0.01}, 0.6439141874016846, 0.6423485467115797),\n",
      "        ({'LR__C': 100}, 0.6439141561292328, 0.6423485467115797),\n",
      "        ({'LR__C': 1000}, 0.6439140801818495, 0.6423484752601439),\n",
      "        ({'LR__C': 1}, 0.6439142231416298, 0.6423483323572721),\n",
      "        ({'LR__C': 0.1}, 0.6439141650642191, 0.6423481894544003),\n",
      "        ({'LR__C': 10}, 0.6439143616339169, 0.6423479751000927),\n",
      "        ({'LR__C': 0.001}, 0.6439140623118769, 0.6423479036486568)],\n",
      " 'RF': [({'RF__max_depth': 5, 'RF__n_estimators': 1000},\n",
      "         0.787567700731761,\n",
      "         0.7756750050826927),\n",
      "        ({'RF__max_depth': 5, 'RF__n_estimators': 500},\n",
      "         0.7874918990388309,\n",
      "         0.7755071781457153),\n",
      "        ({'RF__max_depth': 5, 'RF__n_estimators': 250},\n",
      "         0.78735453907887,\n",
      "         0.7752814901888222),\n",
      "        ({'RF__max_depth': 5, 'RF__n_estimators': 100},\n",
      "         0.7866945508586702,\n",
      "         0.775099413079812),\n",
      "        ({'RF__max_depth': 4, 'RF__n_estimators': 250},\n",
      "         0.7801192381096429,\n",
      "         0.7736012915666932),\n",
      "        ({'RF__max_depth': 4, 'RF__n_estimators': 1000},\n",
      "         0.7803863610180122,\n",
      "         0.7735959828111765),\n",
      "        ({'RF__max_depth': 4, 'RF__n_estimators': 500},\n",
      "         0.7804190126324195,\n",
      "         0.7735812338913112),\n",
      "        ({'RF__max_depth': 4, 'RF__n_estimators': 100},\n",
      "         0.7795388296744978,\n",
      "         0.7734307514662888),\n",
      "        ({'RF__max_depth': 3, 'RF__n_estimators': 100},\n",
      "         0.7753283860147953,\n",
      "         0.7716696697988081),\n",
      "        ({'RF__max_depth': 3, 'RF__n_estimators': 250},\n",
      "         0.7756439783630853,\n",
      "         0.7716394087528601),\n",
      "        ({'RF__max_depth': 3, 'RF__n_estimators': 500},\n",
      "         0.7756101779567794,\n",
      "         0.7716318632635069),\n",
      "        ({'RF__max_depth': 3, 'RF__n_estimators': 1000},\n",
      "         0.7755125808652484,\n",
      "         0.7713487543888521)],\n",
      " 'SVM': [({'SVM__C': 1000}, 0.735184953388546, 0.6333757774328295),\n",
      "         ({'SVM__C': 100}, 0.7038603149114631, 0.6208068523708784),\n",
      "         ({'SVM__C': 10}, 0.6803172249127905, 0.6137002011756165),\n",
      "         ({'SVM__C': 1}, 0.6448918574545968, 0.5874913116048756),\n",
      "         ({'SVM__C': 0.1}, 0.6008003416501095, 0.5567405262262759),\n",
      "         ({'SVM__C': 0.001}, 0.5067461452712383, 0.5004526155235374),\n",
      "         ({'SVM__C': 0.01}, 0.5175052392923326, 0.49297678666422096)]}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(classifiers, X_train, y_train, X_test, y_test, sampler = None):\n",
    "    \"\"\"\n",
    "        Function for plotting roc curves of classifiers for comparison\n",
    "        \n",
    "        :param classifiers: dictionary of classifiers\n",
    "        :param sampler: sampling method to use e.g. SMOTE\n",
    "        \n",
    "        :returns fpr: an array of false positive rate values from roc_curve\n",
    "        :returns tpr: an array of true positive rate values from roc_curve\n",
    "        :returns thresholds: an array of threshold values from roc_curve\n",
    "        :returns roc_auc: roc_auc scores for each classifier in classifiers\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = {}, {}, {}\n",
    "    roc_auc = {}\n",
    "\n",
    "\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "\n",
    "        #set n_jobs = -1 for faster performance\n",
    "        classifier = classifier.set_params(n_jobs = -1)\n",
    "\n",
    "        if sampler:\n",
    "            sampler.set_params(random_state = 42, n_jobs = -1)\n",
    "\n",
    "        steps = [('sampling', sampler),\n",
    "                 (classifier_name, classifier)]\n",
    "\n",
    "        model = Pipeline(steps)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "        fpr[classifier_name], tpr[classifier_name], thresholds[classifier_name] = roc_curve(y_test, y_proba)\n",
    "\n",
    "        roc_auc[classifier_name] = round(auc(fpr[classifier_name], tpr[classifier_name]), 3)\n",
    "\n",
    "        print(classifier_name + ' roc_auc score: ' + str(roc_auc[classifier_name]))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        sns.lineplot(fpr[classifier_name], tpr[classifier_name], err_style = None);\n",
    "\n",
    "    midline_points = np.arange(0, 1.05, 0.05) \n",
    "\n",
    "    plt.plot(midline_points, midline_points, linestyle ='--', color = 'black');\n",
    "    plt.title(\"ROC Curves for Different Classification Models\", y =1.05, fontsize = 16);\n",
    "    plt.xlabel('FPR', fontsize = 12, x = 1.05);\n",
    "    plt.ylabel('TPR', fontsize = 12, rotation =0, y = 1.05);\n",
    "    plt.legend(list(zip(classifiers.keys(), roc_auc.values())));\n",
    "\n",
    "    return fpr, tpr, thresholds, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
